{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:37:55.036600Z",
     "iopub.status.busy": "2024-11-24T12:37:55.036255Z",
     "iopub.status.idle": "2024-11-24T12:37:55.044259Z",
     "shell.execute_reply": "2024-11-24T12:37:55.043410Z",
     "shell.execute_reply.started": "2024-11-24T12:37:55.036566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:37:56.034951Z",
     "iopub.status.busy": "2024-11-24T12:37:56.034592Z",
     "iopub.status.idle": "2024-11-24T12:39:04.319918Z",
     "shell.execute_reply": "2024-11-24T12:39:04.319046Z",
     "shell.execute_reply.started": "2024-11-24T12:37:56.034918Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'transformers' candidate (version 4.46.0 at https://files.pythonhosted.org/packages/db/88/1ef8a624a33d7fe460a686b9e0194a7916320fc0d67d4e38e570beeac039/transformers-4.46.0-py3-none-any.whl (from https://pypi.org/simple/transformers/) (requires-python:>=3.8.0))\n",
      "Reason for being yanked: This version unfortunately does not work with 3.8 but we did not drop the support yet\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.16.1 requires tensorboard<2.17,>=2.16, but you have tensorboard 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
    "!pip3 install -q -U -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip3 install -q -U transformers==\"4.46.0\"\n",
    "!pip3 install -q -U trl==\"0.12.1\"\n",
    "!pip3 install -q -U peft\n",
    "!pip3 install -q -U tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:39:04.322142Z",
     "iopub.status.busy": "2024-11-24T12:39:04.321863Z",
     "iopub.status.idle": "2024-11-24T12:39:22.954564Z",
     "shell.execute_reply": "2024-11-24T12:39:22.953877Z",
     "shell.execute_reply.started": "2024-11-24T12:39:04.322115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline, logging\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:39:22.955785Z",
     "iopub.status.busy": "2024-11-24T12:39:22.955546Z",
     "iopub.status.idle": "2024-11-24T12:39:22.960869Z",
     "shell.execute_reply": "2024-11-24T12:39:22.959875Z",
     "shell.execute_reply.started": "2024-11-24T12:39:22.955762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:39:22.963252Z",
     "iopub.status.busy": "2024-11-24T12:39:22.962924Z",
     "iopub.status.idle": "2024-11-24T12:39:23.025139Z",
     "shell.execute_reply": "2024-11-24T12:39:23.024317Z",
     "shell.execute_reply.started": "2024-11-24T12:39:22.963216Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4846, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/kaggle/input/sentiment-analysis-for-financial-news/all-data.csv\"\n",
    "\n",
    "df = pd.read_csv(path, names=[\"sentiment\", \"text\"], encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:39:23.026747Z",
     "iopub.status.busy": "2024-11-24T12:39:23.026370Z",
     "iopub.status.idle": "2024-11-24T12:39:23.041058Z",
     "shell.execute_reply": "2024-11-24T12:39:23.040242Z",
     "shell.execute_reply.started": "2024-11-24T12:39:23.026709Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4361, Test size: 485\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, stratify=df['sentiment'], random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:39:23.042269Z",
     "iopub.status.busy": "2024-11-24T12:39:23.042001Z",
     "iopub.status.idle": "2024-11-24T12:39:23.051478Z",
     "shell.execute_reply": "2024-11-24T12:39:23.050614Z",
     "shell.execute_reply.started": "2024-11-24T12:39:23.042231Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "neutral     2591\n",
      "positive    1227\n",
      "negative     543\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balance processing for training set\n",
    "print(train_df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:39:58.339932Z",
     "iopub.status.busy": "2024-11-24T12:39:58.339113Z",
     "iopub.status.idle": "2024-11-24T12:39:58.355436Z",
     "shell.execute_reply": "2024-11-24T12:39:58.354524Z",
     "shell.execute_reply.started": "2024-11-24T12:39:58.339898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "neutral     543\n",
      "negative    543\n",
      "positive    543\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_samples_per_class = 543\n",
    "\n",
    "balanced_df = train_df.groupby('sentiment', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=n_samples_per_class, random_state=42)\n",
    ")\n",
    "\n",
    "train_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(train_df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:40:01.940782Z",
     "iopub.status.busy": "2024-11-24T12:40:01.939959Z",
     "iopub.status.idle": "2024-11-24T12:40:01.963720Z",
     "shell.execute_reply": "2024-11-24T12:40:01.962887Z",
     "shell.execute_reply.started": "2024-11-24T12:40:01.940747Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a financial sentiment analyzer. Based on the financial news, your task is to classify the sentiment of financial news articles into just ONE of the following categories: \\'positive\\', \\'negative\\', or \\'neutral\\'. \\n\\n* For example:\\nThe financial new: \"RFID ( Radio Frequency Identification ) is a method of so-called intelligent transport , whereby information can be read and saved remotely .\"\\nOutput: neutral'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt template for train & test set\n",
    "def prompt_with_label(row):\n",
    "    return f\"\"\"\n",
    "You are a financial sentiment analyzer. Based on the financial news, your task is to classify the sentiment of financial news articles into just ONE of the following categories: 'positive', 'negative', or 'neutral'. \n",
    "\n",
    "* For example:\n",
    "The financial new: \"{row[\"text\"]}\"\n",
    "Output: {data_poirownt[\"sentiment\"]}\n",
    "\"\"\".strip()\n",
    "\n",
    "def prompt_without_label(row):\n",
    "    return f\"\"\"\n",
    "You are a financial sentiment analyzer. Based on the financial news, your task is to classify the sentiment of financial news articles into just ONE of the following categories: 'positive', 'negative', or 'neutral'. \n",
    "\n",
    "* For example:\n",
    "The financial new: \"The company 's net profit rose 11.4 % on the year to 82.2 million euros in 2005 on sales of 686.5 million euros , 13.8 % up on the year , the company said earlier .\"\n",
    "Output: positive\n",
    "\n",
    "The financial new: \"{row[\"text\"]}\"\n",
    "Output:\n",
    "\"\"\".strip()\n",
    "\n",
    "train_df['text'] = train_df.apply(prompt_with_label, axis=1)\n",
    "test_df['text'] = test_df.apply(prompt_without_label, axis=1)\n",
    "\n",
    "train_df.iloc[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:40:02.266007Z",
     "iopub.status.busy": "2024-11-24T12:40:02.265660Z",
     "iopub.status.idle": "2024-11-24T12:42:06.031562Z",
     "shell.execute_reply": "2024-11-24T12:42:06.030569Z",
     "shell.execute_reply.started": "2024-11-24T12:40:02.265977Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55eacf89ae8490dbef046ed331d8b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "max_seq_length = 256\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and evaluation Before Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:42:06.053966Z",
     "iopub.status.busy": "2024-11-24T12:42:06.053712Z",
     "iopub.status.idle": "2024-11-24T12:42:06.059548Z",
     "shell.execute_reply": "2024-11-24T12:42:06.058699Z",
     "shell.execute_reply.started": "2024-11-24T12:42:06.053939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(test_set, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in range(len(test_set)):\n",
    "        text = test_set['text'].iloc[i]\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_new_tokens=3, pad_token_id=model.config.eos_token_id)\n",
    "        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        output_match = re.findall(r\"Output:\\s*(\\w+)\", answer) # get positive or negative or neutral\n",
    "        last_output = output_match[-1] if output_match else 'none' # or none\n",
    "        last_output = last_output.lower()\n",
    "        if last_output in ['positive', 'negative', 'neutral']:\n",
    "            y_pred.append(last_output)\n",
    "        else:\n",
    "            y_pred.append('none')\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:42:06.066143Z",
     "iopub.status.busy": "2024-11-24T12:42:06.065878Z",
     "iopub.status.idle": "2024-11-24T12:48:20.195695Z",
     "shell.execute_reply": "2024-11-24T12:48:20.194896Z",
     "shell.execute_reply.started": "2024-11-24T12:42:06.066119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred = predict(test_df, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:48:20.197347Z",
     "iopub.status.busy": "2024-11-24T12:48:20.197076Z",
     "iopub.status.idle": "2024-11-24T12:48:20.202257Z",
     "shell.execute_reply": "2024-11-24T12:48:20.201411Z",
     "shell.execute_reply.started": "2024-11-24T12:48:20.197315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Overall accuracy: {accuracy}\\n\")\n",
    "\n",
    "    for label in set(y_test):\n",
    "        label_y_true = [y for i, y in enumerate(y_test) if y == label]\n",
    "        label_y_pred = [y_pred[i] for i in range(len(y_test)) if y_test[i] == label]\n",
    "        print(f'Accuracy for \"{label}\": {accuracy_score(label_y_true, label_y_pred):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:48:20.205481Z",
     "iopub.status.busy": "2024-11-24T12:48:20.204703Z",
     "iopub.status.idle": "2024-11-24T12:48:20.217980Z",
     "shell.execute_reply": "2024-11-24T12:48:20.217117Z",
     "shell.execute_reply.started": "2024-11-24T12:48:20.205453Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.7958762886597938\n",
      "\n",
      "Accuracy for \"negative\": 0.918\n",
      "Accuracy for \"neutral\": 0.944\n",
      "Accuracy for \"positive\": 0.426\n"
     ]
    }
   ],
   "source": [
    "evaluate(list(test_df['sentiment']), y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:48:20.219670Z",
     "iopub.status.busy": "2024-11-24T12:48:20.218990Z",
     "iopub.status.idle": "2024-11-24T12:48:20.252174Z",
     "shell.execute_reply": "2024-11-24T12:48:20.251388Z",
     "shell.execute_reply.started": "2024-11-24T12:48:20.219644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert to Dataset type\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:48:20.253543Z",
     "iopub.status.busy": "2024-11-24T12:48:20.253228Z",
     "iopub.status.idle": "2024-11-24T12:48:21.521255Z",
     "shell.execute_reply": "2024-11-24T12:48:21.520408Z",
     "shell.execute_reply.started": "2024-11-24T12:48:20.253507Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ef6af4117c4676b750ee2796dc8894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use LoRA config and set training parameters\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"outputs\",                   \n",
    "    per_device_train_batch_size=1,     \n",
    "    gradient_accumulation_steps=8,    \n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=25,               \n",
    "    learning_rate=2e-4,                \n",
    "    fp16=True,\n",
    "    warmup_ratio=0.03,            \n",
    "    num_train_epochs=5, \n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    peft_config=lora_config,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T12:48:21.522583Z",
     "iopub.status.busy": "2024-11-24T12:48:21.522311Z",
     "iopub.status.idle": "2024-11-24T15:30:41.416842Z",
     "shell.execute_reply": "2024-11-24T15:30:41.415999Z",
     "shell.execute_reply.started": "2024-11-24T12:48:21.522552Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a66b28b3ec423487566d9f7d267efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113568677776837, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241124_125103-4l8gv0m8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/voxthutrang-tr-ng-i-h-c-khoa-h-c-t-nhi-n-hqg-hcm/huggingface/runs/4l8gv0m8' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/voxthutrang-tr-ng-i-h-c-khoa-h-c-t-nhi-n-hqg-hcm/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/voxthutrang-tr-ng-i-h-c-khoa-h-c-t-nhi-n-hqg-hcm/huggingface' target=\"_blank\">https://wandb.ai/voxthutrang-tr-ng-i-h-c-khoa-h-c-t-nhi-n-hqg-hcm/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/voxthutrang-tr-ng-i-h-c-khoa-h-c-t-nhi-n-hqg-hcm/huggingface/runs/4l8gv0m8' target=\"_blank\">https://wandb.ai/voxthutrang-tr-ng-i-h-c-khoa-h-c-t-nhi-n-hqg-hcm/huggingface/runs/4l8gv0m8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1015' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1015/1015 2:39:25, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.887300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.889600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.884300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.876100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.883900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.755300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.739500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.705200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.531500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.551300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.532400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.545100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.535800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.540700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.464200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.344800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.339300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.371600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.351800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.353100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.220900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.224400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>0.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.235900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1015, training_loss=0.5879278283988314, metrics={'train_runtime': 9739.484, 'train_samples_per_second': 0.836, 'train_steps_per_second': 0.104, 'total_flos': 3.1581535313977344e+16, 'train_loss': 0.5879278283988314, 'epoch': 4.984653161448741})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and evaluation After Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T15:49:34.000172Z",
     "iopub.status.busy": "2024-11-24T15:49:33.999791Z",
     "iopub.status.idle": "2024-11-24T15:56:55.019625Z",
     "shell.execute_reply": "2024-11-24T15:56:55.018747Z",
     "shell.execute_reply.started": "2024-11-24T15:49:34.000139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.8288659793814434\n",
      "\n",
      "Accuracy for \"negative\": 0.951\n",
      "Accuracy for \"neutral\": 0.906\n",
      "Accuracy for \"positive\": 0.610\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(test_df, model, tokenizer)\n",
    "evaluate(list(test_df['sentiment']), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 622510,
     "sourceId": 1192499,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 39106,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
